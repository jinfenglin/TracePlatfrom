2018-10-24 10:50:12 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 10:50:12 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1a8a8f7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2353b3e6, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@631330c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@42f93a98, org.springframework.test.context.transaction.TransactionalTestExecutionListener@c46bcd4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3234e239]
2018-10-24 10:50:12 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 10:50:12 EDT 2018]; root of context hierarchy
2018-10-24 10:50:13 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 10:50:13 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 10:50:13 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 10:50:13 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 10:50:13 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 10:50:13 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 10:50:13 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 10:50:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:50:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:50:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 10:50:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:50:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:50:13 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 10:50:13 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 10:50:13 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 10:50:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 10:50:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 10:50:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 10:50:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 20
2018-10-24 10:50:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 10:50:14 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 10:50:12 EDT 2018]; root of context hierarchy
2018-10-24 10:50:14 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 10:52:21 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 10:52:21 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7b9a4292, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4a94ee4, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4cc451f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@6379eb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@294425a7, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@67d48005]
2018-10-24 10:52:21 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:52:21 EDT 2018]; root of context hierarchy
2018-10-24 10:52:22 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 10:52:22 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 10:52:22 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 10:52:22 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 10:52:22 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 10:52:22 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 10:52:22 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 10:52:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:52:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:52:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 10:52:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:52:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:52:22 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 10:52:22 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 10:52:22 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 10:52:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 10:52:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 10:52:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 10:52:25 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:52:21 EDT 2018]; root of context hierarchy
2018-10-24 10:52:25 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 10:54:06 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 10:54:06 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7b9a4292, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4a94ee4, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4cc451f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@6379eb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@294425a7, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@67d48005]
2018-10-24 10:54:06 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:54:06 EDT 2018]; root of context hierarchy
2018-10-24 10:54:06 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 10:54:06 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 10:54:07 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 10:54:07 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 10:54:07 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 10:54:07 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 10:54:07 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 10:54:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:54:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:54:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 10:54:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:54:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:54:07 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 10:54:07 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 10:54:07 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 10:54:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 10:54:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 10:54:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 10:54:07 INFO  DummySparkJob:36 - Creating session for spark job exmapleJob
2018-10-24 10:54:27 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:54:06 EDT 2018]; root of context hierarchy
2018-10-24 10:54:27 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 10:55:53 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 10:55:53 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7b9a4292, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4a94ee4, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4cc451f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@6379eb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@294425a7, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@67d48005]
2018-10-24 10:55:53 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:55:53 EDT 2018]; root of context hierarchy
2018-10-24 10:55:54 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 10:55:54 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 10:55:54 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 10:55:54 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 10:55:54 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 10:55:54 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 10:55:54 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 10:55:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:55:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:55:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 10:55:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:55:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:55:55 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 10:55:55 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 10:55:55 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 10:55:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 10:55:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 10:55:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 10:55:55 INFO  DummySparkJob:36 - Creating session for spark job "exmapleJob"
2018-10-24 10:55:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 24
2018-10-24 10:55:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 10:56:05 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 10:56:06 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 10:56:06 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getSparkSession(SparkJob.java:40)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.run(SparkJob.java:81)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 10:56:06 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 10:56:06 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 10:56:06 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 10:56:06 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 10:56:06 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 10:56:06 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 10:56:06 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 60323.
2018-10-24 10:56:06 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 10:56:06 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 10:56:06 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 10:56:06 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 10:56:06 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-ea523592-0a7c-4e78-9bae-d78635ccb77e
2018-10-24 10:56:06 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 10:56:07 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 10:56:07 INFO  log:192 - Logging initialized @14193ms
2018-10-24 10:56:07 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 10:56:07 INFO  Server:414 - Started @14273ms
2018-10-24 10:56:07 INFO  AbstractConnector:278 - Started ServerConnector@e3b4936{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 10:56:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f88ed62{/jobs,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4840cb{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52c4108b{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c0f3cb0{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ebd2df2{/stages,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59a7763b{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f5f2547{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30aec0c2{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54be40a{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77447848{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1898f3a8{/storage,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e7688a9{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c75cd9{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5015f231{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@fcf5e28{/environment,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6516acb8{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b890557{/executors,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2472f06d{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5139d4d5{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11ac126{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12aadfef{/static,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@39a83a96{/,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55e65ff2{/api,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1468a987{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4ee61cce{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 10:56:07 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 10:56:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60338.
2018-10-24 10:56:07 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:60338
2018-10-24 10:56:07 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 10:56:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 60338, None)
2018-10-24 10:56:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:60338 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 60338, None)
2018-10-24 10:56:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 60338, None)
2018-10-24 10:56:07 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 60338, None)
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@729c1298{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 11:03:02 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 11:03:02 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1a8a8f7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2353b3e6, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@631330c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@42f93a98, org.springframework.test.context.transaction.TransactionalTestExecutionListener@c46bcd4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3234e239]
2018-10-24 11:03:02 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:03:02 EDT 2018]; root of context hierarchy
2018-10-24 11:03:03 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 11:03:03 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 11:03:03 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 11:03:03 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 11:03:03 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 11:03:03 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 11:03:03 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 11:03:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:03:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:03:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 11:03:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:03:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:03:03 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 11:03:03 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 11:03:03 INFO  DummySparkJob:36 - Creating session for spark job "exmapleJob"
2018-10-24 11:03:03 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 11:03:03 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:03:02 EDT 2018]; root of context hierarchy
2018-10-24 11:03:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 11:03:03 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 11:03:30 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 11:03:30 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7b9a4292, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4a94ee4, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4cc451f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@6379eb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@294425a7, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@67d48005]
2018-10-24 11:03:30 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 11:03:30 EDT 2018]; root of context hierarchy
2018-10-24 11:03:30 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 11:03:30 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 11:04:45 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 11:04:45 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 11:04:45 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 11:04:45 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 11:04:45 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 11:04:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:04:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:04:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 11:04:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:04:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:04:45 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 11:04:45 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 11:04:45 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 11:04:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 11:04:45 INFO  DummySparkJob:36 - Creating session for spark job "exmapleJob"
2018-10-24 11:04:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 11:04:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 11:04:45 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 11:03:30 EDT 2018]; root of context hierarchy
2018-10-24 11:04:45 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 11:12:16 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 11:12:16 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1a8a8f7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2353b3e6, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@631330c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@42f93a98, org.springframework.test.context.transaction.TransactionalTestExecutionListener@c46bcd4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3234e239]
2018-10-24 11:12:16 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:12:16 EDT 2018]; root of context hierarchy
2018-10-24 11:12:16 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 11:12:16 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 11:12:16 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 11:12:16 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 11:12:16 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 11:12:16 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 11:12:16 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 11:12:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:12:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:12:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 11:12:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:12:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:12:17 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 11:12:17 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 11:12:17 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 11:12:17 INFO  DummySparkJob:36 - Creating session for spark job "exmapleJob"
2018-10-24 11:12:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 11:12:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 11:12:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 11:12:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 26
2018-10-24 11:12:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 11:12:22 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 11:12:22 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 11:12:22 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getSparkSession(SparkJob.java:40)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.run(SparkJob.java:81)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 11:12:22 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 11:12:22 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 11:12:22 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 11:12:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 11:12:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 11:12:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 11:12:22 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61033.
2018-10-24 11:12:22 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 11:12:22 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 11:12:22 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 11:12:22 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 11:12:22 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-ceb922cd-16d8-4a48-b4fd-a0760baf3e34
2018-10-24 11:12:22 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 11:12:22 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 11:12:22 INFO  log:192 - Logging initialized @7186ms
2018-10-24 11:12:22 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 11:12:22 INFO  Server:414 - Started @7244ms
2018-10-24 11:12:22 INFO  AbstractConnector:278 - Started ServerConnector@37f5e8f3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 11:12:22 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 11:12:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70da9a84{/jobs,null,AVAILABLE,@Spark}
2018-10-24 11:12:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a68b79e{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd92dca{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d375c82{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52dcd2fd{/stages,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54ed0211{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31cadb49{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ef0426d{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@987cc69{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1dc82455{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46df54e3{/storage,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad0857f{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1d03e0c8{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41b585b1{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7df1b928{/environment,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53a43094{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@51a38f88{/executors,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3cd60000{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c1ec64b{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ecc6fcc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73de7852{/static,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3db21d8f{/,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4709e197{/api,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b419786{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16f036ef{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 11:12:23 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 11:12:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61046.
2018-10-24 11:12:23 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:61046
2018-10-24 11:12:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 11:12:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 61046, None)
2018-10-24 11:12:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:61046 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 61046, None)
2018-10-24 11:12:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 61046, None)
2018-10-24 11:12:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 61046, None)
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@614607c4{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:27 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:12:16 EDT 2018]; root of context hierarchy
2018-10-24 11:12:27 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 11:12:27 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-10-24 11:12:27 INFO  AbstractConnector:318 - Stopped Spark@37f5e8f3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 11:12:27 INFO  SparkUI:54 - Stopped Spark web UI at http://cse-jcws-07.ND.EDU:4040
2018-10-24 11:12:27 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-10-24 11:12:27 INFO  MemoryStore:54 - MemoryStore cleared
2018-10-24 11:12:27 INFO  BlockManager:54 - BlockManager stopped
2018-10-24 11:12:27 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-10-24 11:12:27 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-10-24 11:12:27 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-10-24 11:12:27 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-10-24 11:12:27 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\jlin6\AppData\Local\Temp\spark-2f7e7134-13aa-4fe2-b257-3a3a9f376f17
2018-10-24 11:14:43 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 11:14:43 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1a8a8f7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2353b3e6, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@631330c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@42f93a98, org.springframework.test.context.transaction.TransactionalTestExecutionListener@c46bcd4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3234e239]
2018-10-24 11:14:43 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:14:43 EDT 2018]; root of context hierarchy
2018-10-24 11:14:44 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 11:14:44 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 11:14:44 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 11:14:44 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 11:14:44 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 11:14:44 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 11:14:44 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 11:14:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:14:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:14:44 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 11:14:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:14:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:14:44 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 11:14:44 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 11:14:44 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 11:14:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 11:14:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 11:14:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 11:14:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 28
2018-10-24 11:14:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 11:14:49 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 11:14:49 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 11:14:50 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getSparkSession(SparkJob.java:39)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.run(SparkJob.java:80)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 11:14:50 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 11:14:50 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 11:14:50 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 11:14:50 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 11:14:50 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 11:14:50 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 11:14:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61175.
2018-10-24 11:14:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 11:14:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 11:14:50 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 11:14:50 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 11:14:50 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-8b8d13a4-af91-4dce-9049-77bc1d169da6
2018-10-24 11:14:50 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 11:14:50 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 11:14:50 INFO  log:192 - Logging initialized @7185ms
2018-10-24 11:14:50 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 11:14:50 INFO  Server:414 - Started @7241ms
2018-10-24 11:14:50 INFO  AbstractConnector:278 - Started ServerConnector@3810c2ca{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 11:14:50 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433d342e{/jobs,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@488ff916{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30202de6{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@558eabd5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62febf3b{/stages,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5380f19f{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3dc4d0fe{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e7c73b8{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45a40ba9{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78098719{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@513f20c5{/storage,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ce368e9{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@97fcf9f{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3dfaa0e6{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@15eb9694{/environment,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62b810e0{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@15cc381f{/executors,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7dd947d0{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@34cf21c9{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16d208a0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@622ac6a5{/static,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5fb9d4{/,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5d4e5993{/api,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@116bbc79{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ef03d4d{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 11:14:50 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 11:14:50 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61188.
2018-10-24 11:14:50 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:61188
2018-10-24 11:14:50 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 11:14:50 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 61188, None)
2018-10-24 11:14:50 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:61188 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 61188, None)
2018-10-24 11:14:50 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 61188, None)
2018-10-24 11:14:50 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 61188, None)
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@616a6bf9{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:51 INFO  SparkContext:54 - Starting job: collect at SparkJob.java:85
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Registering RDD 2 (mapToPair at SparkJob.java:53)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Registering RDD 3 (mapToPair at SparkJob.java:53)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Got job 0 (collect at SparkJob.java:85) with 1 output partitions
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (collect at SparkJob.java:85)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SparkJob.java:53), which has no missing parents
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 3.4 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.1 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on cse-jcws-07.ND.EDU:61188 (size: 2.1 KB, free: 8.3 GB)
2018-10-24 11:14:51 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SparkJob.java:53) (first 15 tasks are for partitions Vector(0))
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at SparkJob.java:53), which has no missing parents
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on cse-jcws-07.ND.EDU:61188 (size: 2.1 KB, free: 8.3 GB)
2018-10-24 11:14:51 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at SparkJob.java:53) (first 15 tasks are for partitions Vector(0))
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes)
2018-10-24 11:14:51 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-10-24 11:14:51 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 944 bytes result sent to driver
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes)
2018-10-24 11:14:51 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 139 ms on localhost (executor driver) (1/1)
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-10-24 11:14:51 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 858 bytes result sent to driver
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (executor driver) (1/1)
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-10-24 11:14:51 INFO  DAGScheduler:54 - ShuffleMapStage 0 (mapToPair at SparkJob.java:53) finished in 0.372 s
2018-10-24 11:14:51 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-10-24 11:14:51 INFO  DAGScheduler:54 - running: Set(ShuffleMapStage 1)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - waiting: Set(ResultStage 2)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - failed: Set()
2018-10-24 11:14:51 INFO  DAGScheduler:54 - ShuffleMapStage 1 (mapToPair at SparkJob.java:53) finished in 0.270 s
2018-10-24 11:14:51 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-10-24 11:14:51 INFO  DAGScheduler:54 - running: Set()
2018-10-24 11:14:51 INFO  DAGScheduler:54 - waiting: Set(ResultStage 2)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - failed: Set()
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[7] at map at SparkJob.java:66), which has no missing parents
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on cse-jcws-07.ND.EDU:61188 (size: 2.7 KB, free: 8.3 GB)
2018-10-24 11:14:51 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at map at SparkJob.java:66) (first 15 tasks are for partitions Vector(0))
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2018-10-24 11:14:51 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2018-10-24 11:14:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2018-10-24 11:14:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2018-10-24 11:14:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2018-10-24 11:14:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2018-10-24 11:14:51 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1573 bytes result sent to driver
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 56 ms on localhost (executor driver) (1/1)
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-10-24 11:14:51 INFO  DAGScheduler:54 - ResultStage 2 (collect at SparkJob.java:85) finished in 0.065 s
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Job 0 finished: collect at SparkJob.java:85, took 0.601774 s
2018-10-24 11:14:51 INFO  AbstractConnector:318 - Stopped Spark@3810c2ca{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 11:14:51 INFO  SparkUI:54 - Stopped Spark web UI at http://cse-jcws-07.ND.EDU:4040
2018-10-24 11:14:51 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-10-24 11:14:51 INFO  MemoryStore:54 - MemoryStore cleared
2018-10-24 11:14:51 INFO  BlockManager:54 - BlockManager stopped
2018-10-24 11:14:51 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-10-24 11:14:51 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-10-24 11:14:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-10-24 11:14:54 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:14:43 EDT 2018]; root of context hierarchy
2018-10-24 11:14:54 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 11:14:54 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-10-24 11:14:54 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\jlin6\AppData\Local\Temp\spark-0a5a5284-79d4-4026-81c5-aa7ba563400b
2018-10-24 12:59:14 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 12:59:14 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@587d1d39, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58c1670b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@6b57696f, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5bb21b69, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6b9651f3, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@38bc8ab5]
2018-10-24 12:59:14 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 12:59:14 EDT 2018]; root of context hierarchy
2018-10-24 12:59:14 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 12:59:14 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 12:59:14 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 12:59:14 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 12:59:14 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 12:59:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 12:59:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 12:59:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 12:59:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 12:59:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 12:59:15 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 12:59:15 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 12:59:15 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 12:59:15 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 12:59:14 EDT 2018]; root of context hierarchy
2018-10-24 12:59:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 13:00:51 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 13:00:51 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@587d1d39, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58c1670b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@6b57696f, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5bb21b69, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6b9651f3, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@38bc8ab5]
2018-10-24 13:00:52 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 13:00:52 EDT 2018]; root of context hierarchy
2018-10-24 13:00:52 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 13:00:52 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 13:00:52 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 13:00:52 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 13:00:52 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 13:00:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 13:00:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 13:00:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 13:00:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 13:00:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 13:00:52 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 13:00:52 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 13:00:52 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 13:00:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 13:00:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 13:00:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 13:00:52 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 13:00:52 EDT 2018]; root of context hierarchy
2018-10-24 13:01:48 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 13:01:48 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@587d1d39, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58c1670b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@6b57696f, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5bb21b69, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6b9651f3, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@38bc8ab5]
2018-10-24 13:01:48 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 13:01:48 EDT 2018]; root of context hierarchy
2018-10-24 13:01:49 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 13:01:49 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 13:01:49 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 13:01:49 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 13:01:49 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 13:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 13:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 13:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 13:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 13:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 13:01:49 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 13:01:49 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 13:01:49 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 13:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 13:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 13:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 13:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 32
2018-10-24 13:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 13:01:54 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 13:01:54 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 13:01:54 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getSparkSession(SparkJob.java:41)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getOrCreateSession(SparkJob.java:88)
	at computationEngine.SparkJobs.LinkPrintSparkJob.call(LinkPrintSparkJob.java:19)
	at computationEngine.SparkJobs.LinkPrintSparkJob.call(LinkPrintSparkJob.java:10)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 13:01:54 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 13:01:55 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 13:01:55 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 13:01:55 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 13:01:55 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 13:01:55 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 13:01:55 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 64530.
2018-10-24 13:01:55 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 13:01:55 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 13:01:55 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 13:01:55 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 13:01:55 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-34a27552-aa6d-474d-96a0-8849592be764
2018-10-24 13:01:55 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 13:01:55 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 13:01:55 INFO  log:192 - Logging initialized @7071ms
2018-10-24 13:01:55 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 13:01:55 INFO  Server:414 - Started @7139ms
2018-10-24 13:01:55 INFO  AbstractConnector:278 - Started ServerConnector@7acd9969{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 13:01:55 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7189e533{/jobs,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1301edda{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@db30297{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b131f8e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3760580b{/stages,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@225253ca{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f280{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@36b21b01{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@99e6ca5{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@613ecf9d{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1120f1f7{/storage,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@376c8ac1{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d6d33cd{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ab84fda{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c01a233{/environment,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f6813f0{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b3fb88b{/executors,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2361f6a9{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6230d8cc{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3d98b0e9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b25ac31{/static,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6aad78dc{/,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@342a40eb{/api,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a96f01{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cd2db8c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 13:01:55 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 13:01:55 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 13:01:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64543.
2018-10-24 13:01:55 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:64543
2018-10-24 13:01:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 13:01:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 64543, None)
2018-10-24 13:01:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:64543 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 64543, None)
2018-10-24 13:01:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 64543, None)
2018-10-24 13:01:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 64543, None)
2018-10-24 13:01:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@544d508b{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 13:01:56 INFO  SparkContext:54 - Starting job: collect at LinkPrintSparkJob.java:21
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Registering RDD 2 (mapToPair at SparkJob.java:54)
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Registering RDD 3 (mapToPair at SparkJob.java:54)
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Got job 0 (collect at LinkPrintSparkJob.java:21) with 1 output partitions
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (collect at LinkPrintSparkJob.java:21)
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SparkJob.java:54), which has no missing parents
2018-10-24 13:01:56 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 5.5 KB, free 8.3 GB)
2018-10-24 13:01:56 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.1 KB, free 8.3 GB)
2018-10-24 13:01:56 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on cse-jcws-07.ND.EDU:64543 (size: 3.1 KB, free: 8.3 GB)
2018-10-24 13:01:56 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SparkJob.java:54) (first 15 tasks are for partitions Vector(0))
2018-10-24 13:01:56 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at SparkJob.java:54), which has no missing parents
2018-10-24 13:01:56 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 5.5 KB, free 8.3 GB)
2018-10-24 13:01:56 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.1 KB, free 8.3 GB)
2018-10-24 13:01:56 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on cse-jcws-07.ND.EDU:64543 (size: 3.1 KB, free: 8.3 GB)
2018-10-24 13:01:56 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at SparkJob.java:54) (first 15 tasks are for partitions Vector(0))
2018-10-24 13:01:56 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2018-10-24 13:01:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes)
2018-10-24 13:01:56 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-10-24 13:01:56 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 901 bytes result sent to driver
2018-10-24 13:01:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes)
2018-10-24 13:01:56 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2018-10-24 13:01:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 94 ms on localhost (executor driver) (1/1)
2018-10-24 13:01:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-10-24 13:01:56 INFO  DAGScheduler:54 - ShuffleMapStage 0 (mapToPair at SparkJob.java:54) finished in 0.286 s
2018-10-24 13:01:56 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-10-24 13:01:56 INFO  DAGScheduler:54 - running: Set(ShuffleMapStage 1)
2018-10-24 13:01:56 INFO  DAGScheduler:54 - waiting: Set(ResultStage 2)
2018-10-24 13:01:56 INFO  DAGScheduler:54 - failed: Set()
2018-10-24 13:01:56 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 901 bytes result sent to driver
2018-10-24 13:01:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 24 ms on localhost (executor driver) (1/1)
2018-10-24 13:01:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-10-24 13:01:56 INFO  DAGScheduler:54 - ShuffleMapStage 1 (mapToPair at SparkJob.java:54) finished in 0.129 s
2018-10-24 13:01:56 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-10-24 13:01:56 INFO  DAGScheduler:54 - running: Set()
2018-10-24 13:01:56 INFO  DAGScheduler:54 - waiting: Set(ResultStage 2)
2018-10-24 13:01:56 INFO  DAGScheduler:54 - failed: Set()
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[7] at map at SparkJob.java:67), which has no missing parents
2018-10-24 13:01:56 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 5.2 KB, free 8.3 GB)
2018-10-24 13:01:56 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.9 KB, free 8.3 GB)
2018-10-24 13:01:56 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on cse-jcws-07.ND.EDU:64543 (size: 2.9 KB, free: 8.3 GB)
2018-10-24 13:01:56 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at map at SparkJob.java:67) (first 15 tasks are for partitions Vector(0))
2018-10-24 13:01:56 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-10-24 13:01:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2018-10-24 13:01:56 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2018-10-24 13:01:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2018-10-24 13:01:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2018-10-24 13:01:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2018-10-24 13:01:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2018-10-24 13:01:56 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1616 bytes result sent to driver
2018-10-24 13:01:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 44 ms on localhost (executor driver) (1/1)
2018-10-24 13:01:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-10-24 13:01:56 INFO  DAGScheduler:54 - ResultStage 2 (collect at LinkPrintSparkJob.java:21) finished in 0.050 s
2018-10-24 13:01:56 INFO  DAGScheduler:54 - Job 0 finished: collect at LinkPrintSparkJob.java:21, took 0.401683 s
2018-10-24 13:01:56 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 13:01:48 EDT 2018]; root of context hierarchy
2018-10-24 13:01:56 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-10-24 13:01:56 INFO  AbstractConnector:318 - Stopped Spark@7acd9969{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 13:01:56 INFO  SparkUI:54 - Stopped Spark web UI at http://cse-jcws-07.ND.EDU:4040
2018-10-24 13:01:56 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-10-24 13:01:56 INFO  MemoryStore:54 - MemoryStore cleared
2018-10-24 13:01:56 INFO  BlockManager:54 - BlockManager stopped
2018-10-24 13:01:56 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-10-24 13:01:56 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-10-24 13:01:56 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-10-24 13:01:56 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-10-24 13:01:56 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\jlin6\AppData\Local\Temp\spark-ecd568fb-bef4-4363-892d-7a16e37e2e9c
2018-10-24 14:23:08 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 14:23:08 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@587d1d39, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58c1670b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@6b57696f, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5bb21b69, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6b9651f3, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@38bc8ab5]
2018-10-24 14:23:08 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 14:23:08 EDT 2018]; root of context hierarchy
2018-10-24 14:23:09 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 14:23:09 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 14:23:09 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 14:23:09 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 14:23:09 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 14:23:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 14:23:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 14:23:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 14:23:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 14:23:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 14:23:09 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 14:23:09 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 14:23:09 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 14:23:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 14:23:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 14:23:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 14:23:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 34
2018-10-24 14:23:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 14:23:14 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 14:23:14 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 14:23:14 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getSparkSession(SparkJob.java:41)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getOrCreateSession(SparkJob.java:88)
	at computationEngine.SparkJobs.LinkPrintSparkJob.call(LinkPrintSparkJob.java:19)
	at computationEngine.SparkJobs.LinkPrintSparkJob.call(LinkPrintSparkJob.java:10)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 14:23:15 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 14:23:15 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 14:23:15 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 14:23:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 14:23:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 14:23:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 14:23:15 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 65266.
2018-10-24 14:23:15 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 14:23:15 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 14:23:15 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 14:23:15 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 14:23:15 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-d3255059-800b-4e32-92cc-77329f6e796e
2018-10-24 14:23:15 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 14:23:15 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 14:23:15 INFO  log:192 - Logging initialized @7283ms
2018-10-24 14:23:15 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 14:23:15 INFO  Server:414 - Started @7357ms
2018-10-24 14:23:15 INFO  AbstractConnector:278 - Started ServerConnector@7b0bc22d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 14:23:15 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c310065{/jobs,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5237abad{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5969524f{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71ce54ad{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ecbf3fa{/stages,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@da32146{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28b3827{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54cbb84b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f5af8f5{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@15dcb2be{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@659a8e0f{/storage,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c9a6b17{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@345fab21{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44e6a656{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@75bda233{/environment,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4ac0bd40{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30f019a{/executors,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@722ac3bb{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a1e4bf7{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25fbd149{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e8317bd{/static,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f2d7939{/,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b96b2aa{/api,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dbf2583{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@51a81bca{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 14:23:15 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 14:23:15 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 14:23:15 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65279.
2018-10-24 14:23:15 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:65279
2018-10-24 14:23:15 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 14:23:15 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 65279, None)
2018-10-24 14:23:15 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:65279 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 65279, None)
2018-10-24 14:23:15 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 65279, None)
2018-10-24 14:23:15 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 65279, None)
2018-10-24 14:23:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dfdb4f0{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 14:23:16 INFO  AbstractConnector:318 - Stopped Spark@7b0bc22d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 14:23:16 INFO  SparkUI:54 - Stopped Spark web UI at http://cse-jcws-07.ND.EDU:4040
2018-10-24 14:23:16 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-10-24 14:23:16 INFO  MemoryStore:54 - MemoryStore cleared
2018-10-24 14:23:16 INFO  BlockManager:54 - BlockManager stopped
2018-10-24 14:23:16 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-10-24 14:23:16 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-10-24 14:23:16 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-10-24 14:23:16 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 14:23:08 EDT 2018]; root of context hierarchy
2018-10-24 14:23:16 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-10-24 14:23:16 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\jlin6\AppData\Local\Temp\spark-a0811952-b271-4b88-9bc9-2f395f6bf751
2018-10-24 14:25:14 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 14:25:14 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@587d1d39, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58c1670b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@6b57696f, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5bb21b69, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6b9651f3, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@38bc8ab5]
2018-10-24 14:25:14 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 14:25:14 EDT 2018]; root of context hierarchy
2018-10-24 14:25:14 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 14:25:14 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 14:25:14 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 14:25:14 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 14:25:14 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 14:25:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 14:25:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 14:25:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 14:25:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 14:25:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 14:25:15 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 14:25:15 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 14:25:15 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 14:25:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 14:25:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 14:25:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 14:25:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 36
2018-10-24 14:25:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 14:25:20 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 14:25:20 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 14:25:20 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getSparkSession(SparkJob.java:41)
	at computationEngine.SparkJobs.LinkGenerationSparkJob.getOrCreateSession(SparkJob.java:88)
	at computationEngine.SparkJobs.LinkPrintSparkJob.call(LinkPrintSparkJob.java:29)
	at computationEngine.SparkJobs.LinkPrintSparkJob.call(LinkPrintSparkJob.java:12)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 14:25:20 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 14:25:20 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 14:25:20 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 14:25:20 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 14:25:20 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 14:25:20 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 14:25:20 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 65334.
2018-10-24 14:25:20 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 14:25:20 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 14:25:20 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 14:25:20 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 14:25:20 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-141a5d38-fe58-42fc-83d1-305510805387
2018-10-24 14:25:20 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 14:25:20 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 14:25:20 INFO  log:192 - Logging initialized @7159ms
2018-10-24 14:25:20 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 14:25:20 INFO  Server:414 - Started @7234ms
2018-10-24 14:25:20 INFO  AbstractConnector:278 - Started ServerConnector@7b0bc22d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 14:25:20 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c310065{/jobs,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5237abad{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5969524f{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71ce54ad{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ecbf3fa{/stages,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@da32146{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28b3827{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54cbb84b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f5af8f5{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@15dcb2be{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@659a8e0f{/storage,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c9a6b17{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@345fab21{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44e6a656{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@75bda233{/environment,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4ac0bd40{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30f019a{/executors,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@722ac3bb{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a1e4bf7{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25fbd149{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e8317bd{/static,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f2d7939{/,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b96b2aa{/api,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dbf2583{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@51a81bca{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 14:25:21 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 14:25:21 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65347.
2018-10-24 14:25:21 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:65347
2018-10-24 14:25:21 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 14:25:21 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 65347, None)
2018-10-24 14:25:21 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:65347 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 65347, None)
2018-10-24 14:25:21 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 65347, None)
2018-10-24 14:25:21 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 65347, None)
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dfdb4f0{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/F:/projects/TracePlatfrom/spark-warehouse').
2018-10-24 14:25:21 INFO  SharedState:54 - Warehouse path is 'file:/F:/projects/TracePlatfrom/spark-warehouse'.
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65b8faba{/SQL,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1c2c6522{/SQL/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18a22937{/SQL/execution,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71847f8a{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-10-24 14:25:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25447313{/static/sql,null,AVAILABLE,@Spark}
2018-10-24 14:25:22 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-10-24 14:25:22 WARN  SparkSession$Builder:66 - Using an existing SparkSession; some configuration may not take effect.
2018-10-24 14:25:22 INFO  AbstractConnector:318 - Stopped Spark@7b0bc22d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 14:25:22 INFO  SparkUI:54 - Stopped Spark web UI at http://cse-jcws-07.ND.EDU:4040
2018-10-24 14:25:22 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-10-24 14:25:22 INFO  MemoryStore:54 - MemoryStore cleared
2018-10-24 14:25:22 INFO  BlockManager:54 - BlockManager stopped
2018-10-24 14:25:22 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-10-24 14:25:22 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-10-24 14:25:22 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-10-24 14:25:22 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@544a2ea6: startup date [Wed Oct 24 14:25:14 EDT 2018]; root of context hierarchy
2018-10-24 14:25:22 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-10-24 14:25:22 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\jlin6\AppData\Local\Temp\spark-16b700a6-3591-4d9e-9fd9-43c7c07ee2e2
2018-10-24 16:35:07 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:35:07 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@27808f31, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@436e852b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@32d2fa64, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1d8d30f7, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3e57cd70, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@9a7504c]
2018-10-24 16:35:07 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@42607a4f: startup date [Wed Oct 24 16:35:07 EDT 2018]; root of context hierarchy
2018-10-24 16:35:07 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:35:07 WARN  GenericApplicationContext:551 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-10-24 16:35:07 ERROR TestContextManager:234 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@32d2fa64] to prepare test instance [SparkEngineTest@1ebd319f]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:106)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:249)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 24 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1107)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 42 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:154)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1155)
	... 53 more
Caused by: java.lang.NullPointerException
	at computationEngine.SparkJobEngine.SparkJobEngine.<init>(SparkJobEngine.java:37)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:142)
	... 55 more
2018-10-24 16:35:27 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:35:27 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:35:27 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:35:27 EDT 2018]; root of context hierarchy
2018-10-24 16:35:27 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:36:41 WARN  GenericApplicationContext:551 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-10-24 16:36:41 ERROR TestContextManager:234 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2] to prepare test instance [SparkEngineTest@59cba5a]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:106)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:249)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 24 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1107)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 42 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:154)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1155)
	... 53 more
Caused by: java.lang.NullPointerException
	at computationEngine.SparkJobEngine.SparkJobEngine.<init>(SparkJobEngine.java:37)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:142)
	... 55 more
2018-10-24 16:39:07 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:39:07 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:39:07 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:39:07 EDT 2018]; root of context hierarchy
2018-10-24 16:39:08 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:39:08 WARN  GenericApplicationContext:551 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-10-24 16:39:08 ERROR TestContextManager:234 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2] to prepare test instance [SparkEngineTest@119cbf96]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:106)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:249)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 24 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1107)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 42 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:154)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1155)
	... 53 more
Caused by: java.lang.NullPointerException
	at computationEngine.SparkJobEngine.SparkJobEngine.<init>(SparkJobEngine.java:39)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:142)
	... 55 more
2018-10-24 16:39:34 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:39:34 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:39:34 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:39:34 EDT 2018]; root of context hierarchy
2018-10-24 16:39:34 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:39:46 WARN  GenericApplicationContext:551 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine$$EnhancerBySpringCGLIB$$74c78a5e]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-10-24 16:39:46 ERROR TestContextManager:234 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2] to prepare test instance [SparkEngineTest@5454d35e]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine$$EnhancerBySpringCGLIB$$74c78a5e]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:106)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:249)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 24 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine$$EnhancerBySpringCGLIB$$74c78a5e]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1107)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 42 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine$$EnhancerBySpringCGLIB$$74c78a5e]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:154)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1155)
	... 53 more
Caused by: java.lang.NullPointerException
	at computationEngine.SparkJobEngine.SparkJobEngine.<init>(SparkJobEngine.java:41)
	at computationEngine.SparkJobEngine.SparkJobEngine$$EnhancerBySpringCGLIB$$74c78a5e.<init>(<generated>)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:142)
	... 55 more
2018-10-24 16:44:47 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:44:47 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@27808f31, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@436e852b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@32d2fa64, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1d8d30f7, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3e57cd70, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@9a7504c]
2018-10-24 16:44:47 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@42607a4f: startup date [Wed Oct 24 16:44:47 EDT 2018]; root of context hierarchy
2018-10-24 16:44:47 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:44:47 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 16:44:48 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 16:44:48 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 16:44:48 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 16:44:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:44:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:44:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 16:44:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:44:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:44:48 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 16:44:48 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 16:44:48 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 16:44:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 16:44:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 16:44:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:44:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 38
2018-10-24 16:44:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 16:45:33 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:45:33 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:45:34 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:45:34 EDT 2018]; root of context hierarchy
2018-10-24 16:45:34 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:45:34 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 16:45:34 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 16:45:34 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 16:45:34 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 16:45:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:45:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:45:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 16:45:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:45:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:45:35 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 16:45:35 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 16:45:35 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 16:45:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 16:45:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 16:45:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:45:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 39
2018-10-24 16:45:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 16:46:50 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:46:50 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:46:50 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:46:50 EDT 2018]; root of context hierarchy
2018-10-24 16:46:50 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:46:51 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 16:46:51 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 16:46:51 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 16:46:51 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 16:46:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:46:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:46:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 16:46:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:46:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:46:51 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 16:46:51 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 16:47:06 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 16:47:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 16:47:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 16:47:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:47:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 41
2018-10-24 16:47:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 16:48:08 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:48:08 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:48:08 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:48:08 EDT 2018]; root of context hierarchy
2018-10-24 16:48:08 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:48:08 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 16:48:09 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 16:48:09 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 16:48:09 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 16:48:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:48:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:48:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 16:48:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:48:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:48:09 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 16:48:09 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 16:50:04 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 16:50:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 16:50:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 16:50:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:50:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 43
2018-10-24 16:50:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 16:50:31 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:50:31 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:50:31 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:50:31 EDT 2018]; root of context hierarchy
2018-10-24 16:50:31 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:50:31 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 16:50:32 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 16:50:32 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 16:50:32 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 16:50:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:50:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:50:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 16:50:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:50:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:50:32 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 16:50:32 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 16:50:36 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 16:50:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 16:50:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 16:50:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:50:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 45
2018-10-24 16:50:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 16:52:03 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:52:03 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:52:03 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:52:03 EDT 2018]; root of context hierarchy
2018-10-24 16:52:03 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:52:03 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 16:52:04 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 16:52:04 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 16:52:04 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 16:52:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:52:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:52:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 16:52:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:52:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:52:04 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 16:52:04 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 16:52:04 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 16:52:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 16:52:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 16:52:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:52:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 47
2018-10-24 16:52:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 16:52:48 INFO  AbstractCoordinator:863 - [Consumer clientId=consumer-1, groupId=TracePlatform] Attempt to heartbeat failed for since member id consumer-1-a9b4b6b0-67ea-4f93-ad28-2479286a74c0 is not valid.
2018-10-24 16:52:48 WARN  ConsumerCoordinator:749 - [Consumer clientId=consumer-1, groupId=TracePlatform] Synchronous auto-commit of offsets {dbserver1.inventory.customers-0=OffsetAndMetadata{offset=9, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2018-10-24 16:52:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 16:52:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:52:48 ERROR ConsumerCoordinator:833 - [Consumer clientId=consumer-1, groupId=TracePlatform] Offset commit failed on partition dbserver1.inventory.customers-0 at offset 9: The coordinator is not aware of this member.
2018-10-24 16:52:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:52:50 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:52:50 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:52:50 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:52:50 EDT 2018]; root of context hierarchy
2018-10-24 16:52:50 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:52:51 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 16:52:51 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 16:52:51 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 16:52:51 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 16:52:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:52:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:52:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 16:52:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 16:52:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 16:52:51 INFO  PlatformMainService:40 - Start Platform main service...
2018-10-24 16:52:51 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 16:52:54 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 16:52:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 16:53:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 16:53:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 16:53:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 52
2018-10-24 16:53:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 16:53:39 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:53:39 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:53:39 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:53:39 EDT 2018]; root of context hierarchy
2018-10-24 16:53:40 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:53:49 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 16:55:06 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:55:06 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:55:06 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:55:06 EDT 2018]; root of context hierarchy
2018-10-24 16:55:06 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:55:07 WARN  GenericApplicationContext:551 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-10-24 16:55:07 ERROR TestContextManager:234 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2] to prepare test instance [SparkEngineTest@59cba5a]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:106)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:249)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 24 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1107)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 42 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:154)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1155)
	... 53 more
Caused by: java.lang.NullPointerException
	at computationEngine.SparkJobEngine.SparkJobEngine.<init>(SparkJobEngine.java:39)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:142)
	... 55 more
2018-10-24 16:55:17 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:55:17 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:55:17 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:55:17 EDT 2018]; root of context hierarchy
2018-10-24 16:55:18 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:55:39 WARN  GenericApplicationContext:551 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-10-24 16:55:39 ERROR TestContextManager:234 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2] to prepare test instance [SparkEngineTest@59cba5a]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:106)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:249)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 24 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1107)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 42 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:154)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1155)
	... 53 more
Caused by: java.lang.NullPointerException
	at computationEngine.SparkJobEngine.SparkJobEngine.<init>(SparkJobEngine.java:39)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:142)
	... 55 more
2018-10-24 16:58:19 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 16:58:19 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 16:58:19 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 16:58:19 EDT 2018]; root of context hierarchy
2018-10-24 16:58:20 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 16:59:02 WARN  GenericApplicationContext:551 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-10-24 16:59:02 ERROR TestContextManager:234 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2] to prepare test instance [SparkEngineTest@59cba5a]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:106)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:249)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 24 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1107)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 42 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:154)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1155)
	... 53 more
Caused by: java.lang.NullPointerException
	at computationEngine.SparkJobEngine.SparkJobEngine.<init>(SparkJobEngine.java:37)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:142)
	... 55 more
2018-10-24 17:00:02 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 17:00:02 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@222545dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5c5eefef, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5158b42f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@595b007d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@72d1ad2e]
2018-10-24 17:00:02 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@1165b38: startup date [Wed Oct 24 17:00:02 EDT 2018]; root of context hierarchy
2018-10-24 17:00:02 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 17:00:18 WARN  GenericApplicationContext:551 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-10-24 17:00:18 ERROR TestContextManager:234 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@16293aa2] to prepare test instance [SparkEngineTest@3d246ea3]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:228)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:287)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:289)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:247)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'platformMainService': Unsatisfied dependency expressed through field 'sparkJobEngine'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128)
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:106)
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:249)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 24 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkJobEngine' defined in file [F:\projects\TracePlatfrom\target\classes\computationEngine\SparkJobEngine\SparkJobEngine.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1107)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585)
	... 42 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [computationEngine.SparkJobEngine.SparkJobEngine]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:154)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1155)
	... 53 more
Caused by: java.lang.NullPointerException
	at computationEngine.SparkJobEngine.SparkJobEngine.<init>(SparkJobEngine.java:40)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:142)
	... 55 more
