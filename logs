2018-10-24 10:50:12 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 10:50:12 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1a8a8f7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2353b3e6, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@631330c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@42f93a98, org.springframework.test.context.transaction.TransactionalTestExecutionListener@c46bcd4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3234e239]
2018-10-24 10:50:12 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 10:50:12 EDT 2018]; root of context hierarchy
2018-10-24 10:50:13 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 10:50:13 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 10:50:13 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 10:50:13 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 10:50:13 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 10:50:13 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 10:50:13 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 10:50:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:50:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:50:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 10:50:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:50:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:50:13 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 10:50:13 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 10:50:13 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 10:50:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 10:50:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 10:50:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 10:50:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 20
2018-10-24 10:50:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 10:50:14 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 10:50:12 EDT 2018]; root of context hierarchy
2018-10-24 10:50:14 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 10:52:21 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 10:52:21 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7b9a4292, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4a94ee4, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4cc451f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@6379eb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@294425a7, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@67d48005]
2018-10-24 10:52:21 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:52:21 EDT 2018]; root of context hierarchy
2018-10-24 10:52:22 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 10:52:22 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 10:52:22 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 10:52:22 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 10:52:22 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 10:52:22 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 10:52:22 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 10:52:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:52:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:52:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 10:52:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:52:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:52:22 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 10:52:22 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 10:52:22 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 10:52:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 10:52:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 10:52:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 10:52:25 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:52:21 EDT 2018]; root of context hierarchy
2018-10-24 10:52:25 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 10:54:06 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 10:54:06 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7b9a4292, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4a94ee4, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4cc451f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@6379eb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@294425a7, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@67d48005]
2018-10-24 10:54:06 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:54:06 EDT 2018]; root of context hierarchy
2018-10-24 10:54:06 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 10:54:06 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 10:54:07 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 10:54:07 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 10:54:07 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 10:54:07 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 10:54:07 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 10:54:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:54:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:54:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 10:54:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:54:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:54:07 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 10:54:07 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 10:54:07 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 10:54:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 10:54:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 10:54:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 10:54:07 INFO  DummySparkJob:36 - Creating session for spark job exmapleJob
2018-10-24 10:54:27 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:54:06 EDT 2018]; root of context hierarchy
2018-10-24 10:54:27 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 10:55:53 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 10:55:53 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7b9a4292, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4a94ee4, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4cc451f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@6379eb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@294425a7, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@67d48005]
2018-10-24 10:55:53 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 10:55:53 EDT 2018]; root of context hierarchy
2018-10-24 10:55:54 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 10:55:54 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 10:55:54 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 10:55:54 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 10:55:54 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 10:55:54 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 10:55:54 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 10:55:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:55:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:55:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 10:55:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 10:55:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 10:55:55 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 10:55:55 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 10:55:55 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 10:55:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 10:55:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 10:55:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 10:55:55 INFO  DummySparkJob:36 - Creating session for spark job "exmapleJob"
2018-10-24 10:55:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 24
2018-10-24 10:55:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 10:56:05 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 10:56:06 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 10:56:06 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJob.getSparkSession(SparkJob.java:40)
	at computationEngine.SparkJob.run(SparkJob.java:81)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 10:56:06 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 10:56:06 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 10:56:06 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 10:56:06 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 10:56:06 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 10:56:06 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 10:56:06 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 60323.
2018-10-24 10:56:06 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 10:56:06 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 10:56:06 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 10:56:06 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 10:56:06 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-ea523592-0a7c-4e78-9bae-d78635ccb77e
2018-10-24 10:56:06 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 10:56:07 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 10:56:07 INFO  log:192 - Logging initialized @14193ms
2018-10-24 10:56:07 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 10:56:07 INFO  Server:414 - Started @14273ms
2018-10-24 10:56:07 INFO  AbstractConnector:278 - Started ServerConnector@e3b4936{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 10:56:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f88ed62{/jobs,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b4840cb{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52c4108b{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c0f3cb0{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ebd2df2{/stages,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59a7763b{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f5f2547{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30aec0c2{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54be40a{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77447848{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1898f3a8{/storage,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e7688a9{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c75cd9{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5015f231{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@fcf5e28{/environment,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6516acb8{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b890557{/executors,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2472f06d{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5139d4d5{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@11ac126{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12aadfef{/static,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@39a83a96{/,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55e65ff2{/api,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1468a987{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4ee61cce{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 10:56:07 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 10:56:07 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 10:56:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60338.
2018-10-24 10:56:07 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:60338
2018-10-24 10:56:07 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 10:56:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 60338, None)
2018-10-24 10:56:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:60338 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 60338, None)
2018-10-24 10:56:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 60338, None)
2018-10-24 10:56:07 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 60338, None)
2018-10-24 10:56:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@729c1298{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 11:03:02 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 11:03:02 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1a8a8f7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2353b3e6, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@631330c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@42f93a98, org.springframework.test.context.transaction.TransactionalTestExecutionListener@c46bcd4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3234e239]
2018-10-24 11:03:02 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:03:02 EDT 2018]; root of context hierarchy
2018-10-24 11:03:03 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 11:03:03 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 11:03:03 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 11:03:03 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 11:03:03 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 11:03:03 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 11:03:03 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 11:03:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:03:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:03:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 11:03:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:03:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:03:03 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 11:03:03 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 11:03:03 INFO  DummySparkJob:36 - Creating session for spark job "exmapleJob"
2018-10-24 11:03:03 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 11:03:03 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:03:02 EDT 2018]; root of context hierarchy
2018-10-24 11:03:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 11:03:03 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 11:03:30 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 11:03:30 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7b9a4292, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4a94ee4, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4cc451f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@6379eb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@294425a7, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@67d48005]
2018-10-24 11:03:30 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 11:03:30 EDT 2018]; root of context hierarchy
2018-10-24 11:03:30 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 11:03:30 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 11:04:45 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 11:04:45 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 11:04:45 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 11:04:45 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 11:04:45 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 11:04:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:04:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:04:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 11:04:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:04:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:04:45 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 11:04:45 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 11:04:45 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 11:04:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 11:04:45 INFO  DummySparkJob:36 - Creating session for spark job "exmapleJob"
2018-10-24 11:04:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 11:04:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 11:04:45 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@206a70ef: startup date [Wed Oct 24 11:03:30 EDT 2018]; root of context hierarchy
2018-10-24 11:04:45 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 11:12:16 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 11:12:16 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1a8a8f7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2353b3e6, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@631330c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@42f93a98, org.springframework.test.context.transaction.TransactionalTestExecutionListener@c46bcd4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3234e239]
2018-10-24 11:12:16 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:12:16 EDT 2018]; root of context hierarchy
2018-10-24 11:12:16 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 11:12:16 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 11:12:16 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 11:12:16 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 11:12:16 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 11:12:16 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 11:12:16 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 11:12:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:12:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:12:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 11:12:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:12:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:12:17 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 11:12:17 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 11:12:17 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 11:12:17 INFO  DummySparkJob:36 - Creating session for spark job "exmapleJob"
2018-10-24 11:12:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 11:12:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 11:12:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 11:12:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 26
2018-10-24 11:12:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 11:12:22 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 11:12:22 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 11:12:22 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJob.getSparkSession(SparkJob.java:40)
	at computationEngine.SparkJob.run(SparkJob.java:81)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 11:12:22 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 11:12:22 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 11:12:22 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 11:12:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 11:12:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 11:12:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 11:12:22 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61033.
2018-10-24 11:12:22 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 11:12:22 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 11:12:22 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 11:12:22 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 11:12:22 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-ceb922cd-16d8-4a48-b4fd-a0760baf3e34
2018-10-24 11:12:22 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 11:12:22 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 11:12:22 INFO  log:192 - Logging initialized @7186ms
2018-10-24 11:12:22 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 11:12:22 INFO  Server:414 - Started @7244ms
2018-10-24 11:12:22 INFO  AbstractConnector:278 - Started ServerConnector@37f5e8f3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 11:12:22 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 11:12:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70da9a84{/jobs,null,AVAILABLE,@Spark}
2018-10-24 11:12:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a68b79e{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd92dca{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d375c82{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52dcd2fd{/stages,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54ed0211{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31cadb49{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ef0426d{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@987cc69{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1dc82455{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46df54e3{/storage,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad0857f{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1d03e0c8{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41b585b1{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7df1b928{/environment,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53a43094{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@51a38f88{/executors,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3cd60000{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c1ec64b{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ecc6fcc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73de7852{/static,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3db21d8f{/,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4709e197{/api,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b419786{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16f036ef{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 11:12:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 11:12:23 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 11:12:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61046.
2018-10-24 11:12:23 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:61046
2018-10-24 11:12:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 11:12:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 61046, None)
2018-10-24 11:12:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:61046 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 61046, None)
2018-10-24 11:12:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 61046, None)
2018-10-24 11:12:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 61046, None)
2018-10-24 11:12:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@614607c4{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 11:12:27 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:12:16 EDT 2018]; root of context hierarchy
2018-10-24 11:12:27 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 11:12:27 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-10-24 11:12:27 INFO  AbstractConnector:318 - Stopped Spark@37f5e8f3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 11:12:27 INFO  SparkUI:54 - Stopped Spark web UI at http://cse-jcws-07.ND.EDU:4040
2018-10-24 11:12:27 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-10-24 11:12:27 INFO  MemoryStore:54 - MemoryStore cleared
2018-10-24 11:12:27 INFO  BlockManager:54 - BlockManager stopped
2018-10-24 11:12:27 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-10-24 11:12:27 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-10-24 11:12:27 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-10-24 11:12:27 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-10-24 11:12:27 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\jlin6\AppData\Local\Temp\spark-2f7e7134-13aa-4fe2-b257-3a3a9f376f17
2018-10-24 11:14:43 INFO  DefaultTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-10-24 11:14:43 INFO  DefaultTestContextBootstrapper:174 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1a8a8f7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2353b3e6, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@631330c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@42f93a98, org.springframework.test.context.transaction.TransactionalTestExecutionListener@c46bcd4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3234e239]
2018-10-24 11:14:43 INFO  GenericApplicationContext:583 - Refreshing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:14:43 EDT 2018]; root of context hierarchy
2018-10-24 11:14:44 INFO  AutowiredAnnotationBeanPostProcessor:155 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-10-24 11:14:44 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService 
2018-10-24 11:14:44 INFO  ThreadPoolTaskExecutor:165 - Initializing ExecutorService  'threadPoolTaskExecutor'
2018-10-24 11:14:44 INFO  AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-10-24 11:14:44 WARN  AdminClientConfig:287 - The configuration 'key.deserializer' was supplied but isn't a known config.
2018-10-24 11:14:44 WARN  AdminClientConfig:287 - The configuration 'value.deserializer' was supplied but isn't a known config.
2018-10-24 11:14:44 WARN  AdminClientConfig:287 - The configuration 'group.id' was supplied but isn't a known config.
2018-10-24 11:14:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:14:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:14:44 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TracePlatform
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-10-24 11:14:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2018-10-24 11:14:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2018-10-24 11:14:44 INFO  PlatformMainService:48 - Start Platform main service...
2018-10-24 11:14:44 INFO  TraceModelManger:34 - start model updating thread...
2018-10-24 11:14:44 INFO  Metadata:273 - Cluster ID: R6BS-zoCTpSdobdfn6jJ5Q
2018-10-24 11:14:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=TracePlatform] Discovered group coordinator 129.74.155.26:9092 (id: 2147483646 rack: null)
2018-10-24 11:14:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=TracePlatform] Revoking previously assigned partitions []
2018-10-24 11:14:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=TracePlatform] (Re-)joining group
2018-10-24 11:14:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=TracePlatform] Successfully joined group with generation 28
2018-10-24 11:14:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=TracePlatform] Setting newly assigned partitions [dbserver1.inventory.customers-0]
2018-10-24 11:14:49 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-10-24 11:14:49 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-24 11:14:50 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at computationEngine.SparkJob.getSparkSession(SparkJob.java:39)
	at computationEngine.SparkJob.run(SparkJob.java:80)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-10-24 11:14:50 INFO  SparkContext:54 - Submitted application: exmapleJob
2018-10-24 11:14:50 INFO  SecurityManager:54 - Changing view acls to: jlin6
2018-10-24 11:14:50 INFO  SecurityManager:54 - Changing modify acls to: jlin6
2018-10-24 11:14:50 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-24 11:14:50 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-24 11:14:50 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jlin6); groups with view permissions: Set(); users  with modify permissions: Set(jlin6); groups with modify permissions: Set()
2018-10-24 11:14:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61175.
2018-10-24 11:14:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-24 11:14:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-24 11:14:50 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-24 11:14:50 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-24 11:14:50 INFO  DiskBlockManager:54 - Created local directory at C:\Users\jlin6\AppData\Local\Temp\blockmgr-8b8d13a4-af91-4dce-9049-77bc1d169da6
2018-10-24 11:14:50 INFO  MemoryStore:54 - MemoryStore started with capacity 8.3 GB
2018-10-24 11:14:50 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-24 11:14:50 INFO  log:192 - Logging initialized @7185ms
2018-10-24 11:14:50 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-24 11:14:50 INFO  Server:414 - Started @7241ms
2018-10-24 11:14:50 INFO  AbstractConnector:278 - Started ServerConnector@3810c2ca{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 11:14:50 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433d342e{/jobs,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@488ff916{/jobs/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30202de6{/jobs/job,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@558eabd5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62febf3b{/stages,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5380f19f{/stages/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3dc4d0fe{/stages/stage,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e7c73b8{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45a40ba9{/stages/pool,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78098719{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@513f20c5{/storage,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ce368e9{/storage/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@97fcf9f{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3dfaa0e6{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@15eb9694{/environment,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62b810e0{/environment/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@15cc381f{/executors,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7dd947d0{/executors/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@34cf21c9{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16d208a0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@622ac6a5{/static,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5fb9d4{/,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5d4e5993{/api,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@116bbc79{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ef03d4d{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-24 11:14:50 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://cse-jcws-07.ND.EDU:4040
2018-10-24 11:14:50 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-10-24 11:14:50 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61188.
2018-10-24 11:14:50 INFO  NettyBlockTransferService:54 - Server created on cse-jcws-07.ND.EDU:61188
2018-10-24 11:14:50 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-24 11:14:50 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 61188, None)
2018-10-24 11:14:50 INFO  BlockManagerMasterEndpoint:54 - Registering block manager cse-jcws-07.ND.EDU:61188 with 8.3 GB RAM, BlockManagerId(driver, cse-jcws-07.ND.EDU, 61188, None)
2018-10-24 11:14:50 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, cse-jcws-07.ND.EDU, 61188, None)
2018-10-24 11:14:50 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, cse-jcws-07.ND.EDU, 61188, None)
2018-10-24 11:14:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@616a6bf9{/metrics/json,null,AVAILABLE,@Spark}
2018-10-24 11:14:51 INFO  SparkContext:54 - Starting job: collect at SparkJob.java:85
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Registering RDD 2 (mapToPair at SparkJob.java:53)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Registering RDD 3 (mapToPair at SparkJob.java:53)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Got job 0 (collect at SparkJob.java:85) with 1 output partitions
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (collect at SparkJob.java:85)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SparkJob.java:53), which has no missing parents
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 3.4 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.1 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on cse-jcws-07.ND.EDU:61188 (size: 2.1 KB, free: 8.3 GB)
2018-10-24 11:14:51 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SparkJob.java:53) (first 15 tasks are for partitions Vector(0))
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at SparkJob.java:53), which has no missing parents
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on cse-jcws-07.ND.EDU:61188 (size: 2.1 KB, free: 8.3 GB)
2018-10-24 11:14:51 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at mapToPair at SparkJob.java:53) (first 15 tasks are for partitions Vector(0))
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes)
2018-10-24 11:14:51 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-10-24 11:14:51 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 944 bytes result sent to driver
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes)
2018-10-24 11:14:51 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 139 ms on localhost (executor driver) (1/1)
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-10-24 11:14:51 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 858 bytes result sent to driver
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (executor driver) (1/1)
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-10-24 11:14:51 INFO  DAGScheduler:54 - ShuffleMapStage 0 (mapToPair at SparkJob.java:53) finished in 0.372 s
2018-10-24 11:14:51 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-10-24 11:14:51 INFO  DAGScheduler:54 - running: Set(ShuffleMapStage 1)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - waiting: Set(ResultStage 2)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - failed: Set()
2018-10-24 11:14:51 INFO  DAGScheduler:54 - ShuffleMapStage 1 (mapToPair at SparkJob.java:53) finished in 0.270 s
2018-10-24 11:14:51 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-10-24 11:14:51 INFO  DAGScheduler:54 - running: Set()
2018-10-24 11:14:51 INFO  DAGScheduler:54 - waiting: Set(ResultStage 2)
2018-10-24 11:14:51 INFO  DAGScheduler:54 - failed: Set()
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[7] at map at SparkJob.java:66), which has no missing parents
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 8.3 GB)
2018-10-24 11:14:51 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on cse-jcws-07.ND.EDU:61188 (size: 2.7 KB, free: 8.3 GB)
2018-10-24 11:14:51 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at map at SparkJob.java:66) (first 15 tasks are for partitions Vector(0))
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7712 bytes)
2018-10-24 11:14:51 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2018-10-24 11:14:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2018-10-24 11:14:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2018-10-24 11:14:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2018-10-24 11:14:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2018-10-24 11:14:51 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1573 bytes result sent to driver
2018-10-24 11:14:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 56 ms on localhost (executor driver) (1/1)
2018-10-24 11:14:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-10-24 11:14:51 INFO  DAGScheduler:54 - ResultStage 2 (collect at SparkJob.java:85) finished in 0.065 s
2018-10-24 11:14:51 INFO  DAGScheduler:54 - Job 0 finished: collect at SparkJob.java:85, took 0.601774 s
2018-10-24 11:14:51 INFO  AbstractConnector:318 - Stopped Spark@3810c2ca{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-24 11:14:51 INFO  SparkUI:54 - Stopped Spark web UI at http://cse-jcws-07.ND.EDU:4040
2018-10-24 11:14:51 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-10-24 11:14:51 INFO  MemoryStore:54 - MemoryStore cleared
2018-10-24 11:14:51 INFO  BlockManager:54 - BlockManager stopped
2018-10-24 11:14:51 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-10-24 11:14:51 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-10-24 11:14:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-10-24 11:14:54 INFO  GenericApplicationContext:984 - Closing org.springframework.context.support.GenericApplicationContext@78ac1102: startup date [Wed Oct 24 11:14:43 EDT 2018]; root of context hierarchy
2018-10-24 11:14:54 INFO  ThreadPoolTaskExecutor:202 - Shutting down ExecutorService 'threadPoolTaskExecutor'
2018-10-24 11:14:54 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-10-24 11:14:54 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\jlin6\AppData\Local\Temp\spark-0a5a5284-79d4-4026-81c5-aa7ba563400b
